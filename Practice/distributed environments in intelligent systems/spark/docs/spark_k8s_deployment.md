# –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ Spark Standalone Cluster –Ω–∞ Kubernetes

–£—Å–æ–≤–∏–∫ –°.–í. (usovik@mirea.ru)

## –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

- –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Minikube
- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –æ–±—Ä–∞–∑–∞ Spark
- –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ Spark –Ω–∞ Kubernetes
- –¢–µ—Å—Ç Spark Pi
- –û—á–∏—Å—Ç–∫–∞
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

## –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

–î–ª—è –Ω–∞—á–∞–ª–∞ –≤–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–¥–µ–ª–∞—Ç—å —Å–ª–µ–¥—É—é—â–µ–µ:
- –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ Docker. –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ, –∫–∞–∫ —ç—Ç–æ —Å–¥–µ–ª–∞—Ç—å [–∑–¥–µ—Å—å](https://docs.docker.com/install/linux/docker-ce/ubuntu/)

## –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Minikube

–ö–∞–∫ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç `minikube` –≤—ã –º–æ–∂–µ—Ç–µ –Ω–∞–π—Ç–∏  [–∑–¥–µ—Å—å](install_minikube.md).

## –ó–∞–ø—É—Å–∫ Kubernetes

–ß—Ç–æ–±—ã –∑–∞–ø—É—Å—Ç–∏—Ç—å K8S, –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —Å–ª–µ–¥—É—é—â—É—é –∫–æ–º–∞–Ω–¥—É:

`sudo minikube start --vm-driver=none`

```
üòÑ  minikube v1.6.1 on Ubuntu 18.04 (vbox/amd64)
...
ü§π  Running on localhost (CPUs=4, Memory=7974MB, Disk=60217MB) ...
...
‚ÑπÔ∏è   OS release is Ubuntu 18.04.3 LTS
üê≥  Preparing Kubernetes v1.17.0 on Docker '19.03.5' ...
    ‚ñ™ kubelet.resolv-conf=/run/systemd/resolve/resolv.conf
...
üèÑ  Done! kubectl is now configured to use "minikube"
```

–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –∏ –ø–∞–º—è—Ç–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤–∞—à–∏–º –∫–ª–∞—Å—Ç–µ—Ä–æ–º. –û–¥–Ω–∞–∫–æ –æ–Ω–∏ –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å –ø—Ä–∏–º–µ–Ω–µ–Ω—ã –≤ —Ä–µ–∂–∏–º–µ 'none' –≤ driver mode.

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–∞:

`sudo minikube status`

```
host: Running
kubelet: Running
apiserver: Running
kubeconfig: Configured
```

–í—ã –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å –∫–ª–∞—Å—Ç–µ—Ä –ø–æ–∑–∂–µ, –∫–æ–≥–¥–∞ —Å–æ–∑–¥–∞–¥–∏—Ç–µ –æ–±—Ä–∞–∑ Spark –∏ —Å–æ–∑–¥–∞–¥–∏—Ç–µ –¥—Ä—É–≥–∏–µ —Ñ–∞–π–ª—ã.

## –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –æ–±—Ä–∞–∑–∞ Spark

Spark 2.3 –∏ –±–æ–ª–µ–µ –ø–æ–∑–¥–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ –∏–º–µ—é—Ç Docker-—Ñ–∞–π–ª –≤ —Å–≤–æ–µ–º –¥–æ–º–∞—à–Ω–µ–º –∫–∞—Ç–∞–ª–æ–≥–µ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—Ä–∞–∑–∞ Spark. –ü–æ—ç—Ç–æ–º—É —Å–∫–∞—á–∞–π—Ç–µ Spark 2.4.4 –∏ —Å–æ–±–µ—Ä–∏—Ç–µ –æ–±—Ä–∞–∑.

#### –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–∏—Å—Ç—Ä–∏–±—É—Ç–∏–≤–∞ Spark

–ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ –¥–æ–º–∞—à–Ω–∏–π –∫–∞—Ç–∞–ª–æ–≥:

```
cd $HOME
```

–°–∫–∞—á–∞–π—Ç–µ Spark 2.4.4, —Ä–∞—Å–ø–∞–∫—É–π—Ç–µ –µ–≥–æ –∏ —É–¥–∞–ª–∏—Ç–µ –∏—Å—Ö–æ–¥–Ω—ã–π –∞—Ä—Ö–∏–≤:

```
mkdir spark \
    && wget -P sources https://archive.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz \
    && tar -xvf sources/spark-2.4.4-bin-hadoop2.7.tgz --directory spark --strip-components 1 \
    && rm sources/spark-2.4.4-bin-hadoop2.7.tgz
```

#### –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –æ–±—Ä–∞–∑–∞ Spark

–°–æ–∑–¥–∞–π—Ç–µ –æ–±—Ä–∞–∑, –∑–∞–ø—É—Å—Ç–∏–≤ —Å–ª–µ–¥—É—é—â–∏–π —Å–∫—Ä–∏–ø—Ç –≤ –¥–æ–º–∞—à–Ω–µ–º –∫–∞—Ç–∞–ª–æ–≥–µ Spark:

`cd $SPARK_HOME && bin/docker-image-tool.sh build`

```
...
Successfully built e5d13f574244
Successfully tagged spark:latest
...
Successfully built 6343567afd81
Successfully tagged spark-py:latest
...
Successfully built e20c83c11bb8
Successfully tagged spark-r:latest
```

–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:

`docker image ls`

```
REPOSITORY                                TAG                 IMAGE ID            CREATED              SIZE
spark-r                                   latest              e20c83c11bb8        About a minute ago   760MB
spark-py                                  latest              6343567afd81        5 minutes ago        466MB
spark                                     latest              e5d13f574244        6 minutes ago        375MB
```

Docker-—Ñ–∞–π–ª –∏ —Å–∫—Ä–∏–ø—Ç entrypoint –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –∑–¥–µ—Å—å: `$SPARK_HOME/spark/kubernetes/dockerfiles/spark`.

#### –ò–∑–º–µ–Ω–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –æ–±—Ä–∞–∑–∞ 

–ß—Ç–æ–±—ã —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—å Spark –≤ Kubernetes —Å –ø–æ–º–æ—â—å—é –≤–µ—Ä—Å–∏–∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è, –Ω–∞–º –Ω—É–∂–Ω–æ –Ω–µ–º–Ω–æ–≥–æ –∏–∑–º–µ–Ω–∏—Ç—å —Å–æ–∑–¥–∞–Ω–Ω—ã–π –æ–±—Ä–∞–∑, —á—Ç–æ–±—ã –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π entrypoint. –≠—Ç–æ—Ç –æ–±—Ä–∞–∑ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —É–∑–ª–æ–≤ Spark master –∏ workers.

–ï—Å—Ç—å –¥–≤–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Å–∫—Ä–∏–ø—Ç–∞: –ø–µ—Ä–≤—ã–π –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –∏ –≤—Ç–æ—Ä–æ–π –¥–ª—è –∏—Ö –æ—Å—Ç–∞–Ω–æ–≤–∫–∏.

–°—Ç–∞—Ä—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –≤—ã–≥–ª—è–¥–∏—Ç —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:

```bash
#!/bin/bash

case "$1" in
    master)
        echo "MASTER"
        exec tini -s -- /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master --host $HOSTNAME --port 7077 --webui-port 8080
        ;;
    worker)
        echo "WORKER"
        MASTER_IP_ADDRESSES=( $( nslookup $MASTER_IP_RESOLVER | awk '/^Address / { print $3 }') )
        if [ ${#MASTER_IP_ADDRESSES[@]} ] && [ -n ${MASTER_IP_ADDRESSES[0]} ]; 
        then
            echo ${MASTER_IP_ADDRESSES[0]} $MASTER_HOSTNAME >> /etc/hosts
            exec tini -s -- /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://$MASTER_HOSTNAME:7077
        else
            echo "Master IP was not found" 1>&2
            exit 1
        fi
        ;;
    *)
        echo $"Usage: $0 {master|worker}" 1>&2
        exit 1
esac
```

–¢–µ–ø–µ—Ä—å —Å–æ–∑–¥–∞–π—Ç–µ Dockerfile —Å–æ —Å–ª–µ–¥—É—é—â–∏–º —Å–æ–¥–µ—Ä–∂–∏–º—ã–º:

```dockerfile
FROM spark:latest

LABEL maintainer="Sergei Papulin <papulin.study@yandex.ru>"

ENV PATH="$SPARK_HOME/bin:${PATH}"
COPY ["./start-spark.sh", "./stop-spark.sh", "/opt/"]
RUN chmod 755 /opt/start-spark.sh /opt/stop-spark.sh
```

–°–æ–∑–¥–∞–π—Ç–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –æ–±—Ä–∞–∑ Spark, –∏—Å–ø–æ–ª—å–∑—É—è —Å–æ–∑–¥–∞–Ω–Ω—ã–π Docker-—Ñ–∞–π–ª:

`cd $REPO/projects/k8s/spark/ && docker build -t custom-spark:v2.4.4 .`

```
Sending build context to Docker daemon  11.26kB
Step 1/5 : FROM spark:latest
 ---> e5d13f574244
Step 2/5 : LABEL maintainer="Sergei Papulin <papulin.study@yandex.ru>"
 ---> Running in 9de96c753974
Removing intermediate container 9de96c753974
 ---> 050bb6981f5e
Step 3/5 : ENV PATH="$SPARK_HOME/bin:${PATH}"
 ---> Running in e05dc93b02fd
Removing intermediate container e05dc93b02fd
 ---> 80882ed1ba66
Step 4/5 : COPY ["./start-spark.sh", "./stop-spark.sh", "/opt/"]
 ---> 1fc7c09a9537
Step 5/5 : RUN chmod 755 /opt/start-spark.sh /opt/stop-spark.sh
 ---> Running in 84a3537e2867
Removing intermediate container 84a3537e2867
 ---> 66e2167651e5
Successfully built 66e2167651e5
Successfully tagged custom-spark:v2.4.4
```

–í—ã–≤–æ–¥ —Å–ø–∏—Å–∫–∞ –æ–±—Ä–∞–∑–æ–≤:

`docker image ls`

```
REPOSITORY                                TAG                 IMAGE ID            CREATED             SIZE
custom-spark                              v2.4.4              66e2167651e5        34 seconds ago      375MB
spark-r                                   latest              e20c83c11bb8        10 minutes ago      760MB
spark-py                                  latest              6343567afd81        14 minutes ago      466MB
spark                                     latest              e5d13f574244        16 minutes ago      375MB
```

–í—ã –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ç–æ—Ä bash –≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–º –æ–±—Ä–∞–∑–µ –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –≤—Å–µ —Å–∫—Ä–∏–ø—Ç—ã —É—Å–ø–µ—à–Ω–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω—ã:

`docker run --name custom-spark-test -it custom-spark:v2.4.4 /bin/bash`

```
bash-4.4# ls /opt/
entrypoint.sh   spark           start-spark.sh  stop-spark.sh
bash-4.4# exit
```

–£–¥–∞–ª–∏—Ç–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä, –≤ –∫–æ—Ç–æ—Ä–æ–º –±—ã–ª –∑–∞–ø—É—â–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –æ–±—Ä–∞–∑.

–í—ã–≤–µ–¥–∏—Ç–µ –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä:

`docker container ls -l`

```
CONTAINER ID        IMAGE                 COMMAND                  CREATED             STATUS                     PORTS               NAMES
7634f6045524        custom-spark:v2.4.4   "/opt/entrypoint.sh ‚Ä¶"   3 minutes ago       Exited (0) 2 minutes ago                       custom-spark-test
```

–£–¥–∞–ª–∏—Ç–µ –µ–≥–æ –ø–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—É –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞:

`docker container rm 7634f6045524`

## –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ Spark –≤ Kubernetes

–ß—Ç–æ–±—ã —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—å Spark, –¥–∞–≤–∞–π—Ç–µ —Å–æ–∑–¥–∞–¥–∏–º –¥–≤–∞ —Ñ–∞–π–ª–∞ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è yaml –¥–ª—è –∑–∞–ø—É—Å–∫–∞ master –∏ worker —É–∑–ª–æ–≤. –§–∞–π–ª—ã —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è —Å–æ–¥–µ—Ä–∂–∞—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—é –º–æ–¥—É–ª–µ–π –¥–µ–∫–ª–∞—Ä–∞—Ç–∏–≤–Ω—ã–º —Å–ø–æ—Å–æ–±–æ–º.

–ö—Ä–æ–º–µ —Ç–æ–≥–æ, –º—ã —Å–æ–∑–¥–∞–µ–º yaml-—Ñ–∞–π–ª —Å–ª—É–∂–±—ã, —á—Ç–æ–±—ã –æ—Ç–∫—Ä—ã—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ä—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞, –∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ö–∞–Ω–∏–∑–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ IP-–∞–¥—Ä–µ—Å–∞ –≤ workers.

#### –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ Master

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-master-deployment
  namespace: spark
  labels:
    environment: dev
    app: spark
    role: master
    version: 2.4.4
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark
      role: master
  template:
    metadata:
      labels:
        app: spark
        role: master
    spec:
      hostname: spark-master
      containers:
        - name: spark-master
          image: custom-spark:v2.4.4
          imagePullPolicy: IfNotPresent
          command: ["/opt/start-spark.sh"]
          args: ["master"]
          ports:
            - containerPort: 7077
            - containerPort: 8080
          resources:
            requests:
              cpu: 500m
          lifecycle:
            preStop:
              exec:
                command: ["/opt/stop-spark.sh", "master"]
```

#### –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ Worker

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-worker-deployment
  namespace: spark
  labels:
    environment: dev
    app: spark
    role: worker
    version: 2.4.4
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark
      role: worker
  template:
    metadata:
      labels:
        app: spark
        role: worker
    spec:
      containers:
        - name: spark-worker
          image: custom-spark:v2.4.4
          imagePullPolicy: IfNotPresent
          env:
            - name: MASTER_IP_RESOLVER
              value: "*.spark-master-service.spark.svc.cluster.local"
            - name: MASTER_HOSTNAME
              value: "spark-master"
          command: ["/opt/start-spark.sh"]
          args: ["worker"]
          resources:
            requests:
              cpu: 500m
          lifecycle:
            preStop:
              exec:
                command: ["/opt/stop-spark.sh", "worker"]
```

#### –°–ª—É–∂–±—ã

```yaml
apiVersion: v1
kind: Service
metadata:
  name: spark-master-service
  namespace: spark
  labels:
    environment: dev
    app: spark
    role: master
    version: 2.4.4
spec:
  selector:
    app: spark
    role: master
  ports:
    - protocol: TCP
      port: 9999
      targetPort: 8080
```


#### –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –∏ —Å–ª—É–∂–µ–±–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤

–ï—Å–ª–∏ –≤—ã –µ—â–µ –Ω–µ –∑–∞–ø—É—Å–∫–∞–ª–∏ K8S, —Å–∞–º–æ–µ –≤—Ä–µ–º—è —ç—Ç–æ —Å–¥–µ–ª–∞—Ç—å.

–°–æ–∑–¥–∞–π—Ç–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –∏–º–µ–Ω `spark`:

`sudo kubectl create namespace spark`

```
namespace/spark created
```

–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–ª—É–∂–±—É:

`sudo kubectl apply -f $REPO/projects/k8s/spark/spark-master-service.yaml`

```
service/spark-master-service created
```

–í—ã–≤–µ—Å—Ç–∏ –≤—Å–µ —Å–µ—Ä–≤–∏—Å—ã –∏–∑ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –∏–º–µ–Ω `spark`:

`sudo kubectl get services -n spark`

```
NAME                   TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE
spark-master-service   ClusterIP   10.96.66.194   <none>        9999/TCP   12s
```

–ó–∞—Ç–µ–º –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ master:

`sudo kubectl apply -f $REPO/projects/k8s/spark/spark-master-deployment.yaml`

```
deployment.apps/spark-master-deployment created
```

–ò —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ worker:

`sudo kubectl apply -f $REPO/projects/k8s/spark/spark-worker-deployment.yaml`

```
deployment.apps/spark-worker-deployment created
```

`sudo kubectl get deployments -n spark`

```
NAME                      READY   UP-TO-DATE   AVAILABLE   AGE
spark-master-deployment   1/1     1            1           21s
spark-worker-deployment   1/1     1            1           11s
```

–û—Ç–æ–±—Ä–∞–∑–∏—Ç—å –≤—Å–µ –∑–∞–ø—É—â–µ–Ω–Ω—ã–µ –º–æ–¥—É–ª–∏ –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –∏–º–µ–Ω `spark`:

`sudo kubectl get pods -n spark -o wide`

```
NAME                                       READY   STATUS    RESTARTS   AGE   IP           NODE       NOMINATED NODE   READINESS GATES
spark-master-deployment-85b688cfbb-mbznc   1/1     Running   0          37s   172.17.0.4   minikube   <none>           <none>
spark-worker-deployment-5dfd4b788d-5ghfq   1/1     Running   0          26s   172.17.0.5   minikube   <none>           <none>
```

–ß—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –∂—É—Ä–Ω–∞–ª—ã –∏–∑ master –º–æ–¥—É–ª—è, –≤—ã –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–ª–µ–¥—É—é—â—É—é –∫–æ–º–∞–Ω–¥—É:

`sudo kubectl logs spark-master-deployment-85b688cfbb-mbznc -n spark`

```
MASTER
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
INFO Master: Started daemon with process name: 6@spark-master
...
INFO Utils: Successfully started service 'sparkMaster' on port 7077.
INFO Master: Starting Spark master at spark://spark-master:7077
INFO Master: Running Spark version 2.4.4
INFO Utils: Successfully started service 'MasterUI' on port 8080.
INFO MasterWebUI: Bound MasterWebUI to 0.0.0.0, and started at http://spark-master:8080
INFO Master: I have been elected leader! New state: ALIVE
```

–í—ã –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å `bash` —Ç–∞–∫ –∂–µ, –∫–∞–∫ –∏ –¥–ª—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ Docker:

`sudo kubectl exec -it spark-master-deployment-85b688cfbb-mbznc -n spark -- /bin/bash`

#### –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ workers

A–ö–∞–∫ –≤—ã –º–æ–≥–ª–∏ –∑–∞–º–µ—Ç–∏—Ç—å, —É –Ω–∞—Å —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω worker. –ß—Ç–æ–±—ã —É–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ worker –¥–æ 3, –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —Å–ª–µ–¥—É—é—â—É—é –∫–æ–º–∞–Ω–¥—É —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º `replicas`, —Ä–∞–≤–Ω—ã–º 3:

`sudo kubectl scale deployment.v1.apps/spark-worker-deployment --replicas=3 -n spark`

```
deployment.apps/spark-worker-deployment scaled
```

–¢–µ–ø–µ—Ä—å –æ—Ç–æ–±—Ä–∞–∑–∏—Ç–µ –≤—Å–µ worker –º–æ–¥—É–ª–∏:

`sudo kubectl get pods -l app=spark,role=worker -o wide -n spark`

```
NAME                                       READY   STATUS    RESTARTS   AGE   IP           NODE       NOMINATED NODE   READINESS GATES
spark-worker-deployment-5dfd4b788d-5ghfq   1/1     Running   0          94s   172.17.0.5   minikube   <none>           <none>
spark-worker-deployment-5dfd4b788d-q94p5   1/1     Running   0          10s   172.17.0.6   minikube   <none>           <none>
spark-worker-deployment-5dfd4b788d-qc4f2   1/1     Running   0          10s   172.17.0.7   minikube   <none>           <none>
```

–û—Ç–∫—Ä–æ–π—Ç–µ –±—Ä–∞—É–∑–µ—Ä –∏ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –ø–æ –∞–¥—Ä–µ—Å—É `10.96.66.194:9999` (—Å–º. IP-–∞–¥—Ä–µ—Å —Å–ª—É–∂–±—ã), —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å:![Spark Master Web UI](img/minikube/spark_k8s_dep_1.png "Spark Master Web UI")

<center><i>–†–∏—Å—É–Ω–æ–∫ 1. Spark Master Web UI</i></center>

## –ó–∞–ø—É—Å–∫ Pi —Ç–µ—Å—Ç–∞

–ü—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞—à –∫–ª–∞—Å—Ç–µ—Ä Spark ‚Äî –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ Pi, –∫–æ—Ç–æ—Ä–æ–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –∫–∞—Ç–∞–ª–æ–≥–µ `examples`:

```
sudo kubectl exec spark-master-deployment-85b688cfbb-mbznc -n spark -- \
  spark-submit \
    --master spark://spark-master:7077 \
    --name spark-pi \
    --class org.apache.spark.examples.SparkPi \
    local:///opt/spark/examples/jars/spark-examples_2.11-2.4.4.jar
```

```
...
INFO DAGScheduler: Job 0 finished: reduce at SparkPi.scala:38, took 6.191359 s
Pi is roughly 3.137515687578438
INFO SparkUI: Stopped Spark web UI at http://spark-master:4040
INFO StandaloneSchedulerBackend: Shutting down all executors
...
```

![Running Application](img/minikube/spark_k8s_dep_2.png "Running Application")
<center><i>–†–∏—Å—É–Ω–æ–∫ 2. –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è</i></center>

![Application Details](img/minikube/spark_k8s_dep_3.png "Application Details")
<center><i>–†–∏—Å—É–Ω–æ–∫ 3. –°–≤–µ–¥–µ–Ω–∏—è –æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏</i></center>

## –û—á–∏—Å—Ç–∫–∞

–ß—Ç–æ–±—ã —É–¥–∞–ª–∏—Ç—å —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è —Å –∏—Ö –º–æ–¥—É–ª—è–º–∏, –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —Å–ª–µ–¥—É—é—â—É—é –∫–æ–º–∞–Ω–¥—É:

`sudo kubectl delete deployment spark-worker-deployment spark-master-deployment -n spark`

```
deployment.apps "spark-worker-deployment" deleted
deployment.apps "spark-master-deployment" deleted
```

–£–¥–∞–ª–µ–Ω–∏–µ —Å–ª—É–∂–±—ã:

`sudo kubectl delete service spark-master-service -n spark`

```
service "spark-master-service" deleted
```

–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞:

`sudo minikube stop`

```
‚úã  Stopping "minikube" in none ...
‚úã  Stopping "minikube" in none ...
üõë  "minikube" stopped.
```

–£–¥–∞–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–∞:

`sudo minikube delete`

```
üîÑ  Uninstalling Kubernetes v1.17.0 using kubeadm ...
üî•  Deleting "minikube" in none ...
üíî  The "minikube" cluster has been deleted.
üî•  Successfully deleted profile "minikube"
```


## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

- [Kubernetes: Deployments](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/)
- [Kubernetes: Service](https://kubernetes.io/docs/concepts/services-networking/service/)
- [Deploying Spark on Kubernetes](https://github.com/testdrivenio/spark-kubernetes)

